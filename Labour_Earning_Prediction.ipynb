{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CONCLUSION -The objective of this analysis is to explore and predict outcomes based on the given dataset using data preprocessing, exploratory data analysis (EDA), and machine learning techniques. The project aims to uncover patterns within the data and build an accurate predictive model to support decision-making based on the identified features.\n",
        "\n",
        "\n",
        "\n",
        "- Prathmesh Maurya"
      ],
      "metadata": {
        "id": "auDZMiqR04bF"
      },
      "id": "auDZMiqR04bF"
    },
    {
      "cell_type": "markdown",
      "id": "fa7358dc-7d6c-4b95-9c4a-6ac048db1bb6",
      "metadata": {
        "id": "fa7358dc-7d6c-4b95-9c4a-6ac048db1bb6"
      },
      "source": [
        "####  Step 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4927ea7-cb2e-4d82-86f1-441b2ddcb323",
      "metadata": {
        "id": "a4927ea7-cb2e-4d82-86f1-441b2ddcb323"
      },
      "outputs": [],
      "source": [
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af2ce386-c98e-4bb6-9fbb-9e8c0fb50b78",
      "metadata": {
        "id": "af2ce386-c98e-4bb6-9fbb-9e8c0fb50b78"
      },
      "source": [
        "#### Step 2: Load and Explore the Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36428877-86c6-468a-a82f-340d6f68b291",
      "metadata": {
        "id": "36428877-86c6-468a-a82f-340d6f68b291",
        "outputId": "e8c512b5-eebf-474e-ebcf-0a724e0ffb58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Age          Eduacation      Race         Hisp MaritalStatus  Nodeg  \\\n",
            "0   45  LessThanHighSchool  NotBlack  NotHispanic       Married      1   \n",
            "1   21        Intermediate  NotBlack  NotHispanic    NotMarried      0   \n",
            "2   38          HighSchool  NotBlack  NotHispanic       Married      0   \n",
            "3   48  LessThanHighSchool  NotBlack  NotHispanic       Married      1   \n",
            "4   18  LessThanHighSchool  NotBlack  NotHispanic       Married      1   \n",
            "\n",
            "   Earnings_1974  Earnings_1975  Earnings_1978  \n",
            "0      21516.670      25243.550      25564.670  \n",
            "1       3175.971       5852.565      13496.080  \n",
            "2      23039.020      25130.760      25564.670  \n",
            "3      24994.370      25243.550      25564.670  \n",
            "4       1669.295      10727.610       9860.869  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15992 entries, 0 to 15991\n",
            "Data columns (total 9 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Age            15992 non-null  int64  \n",
            " 1   Eduacation     15992 non-null  object \n",
            " 2   Race           15992 non-null  object \n",
            " 3   Hisp           15992 non-null  object \n",
            " 4   MaritalStatus  15992 non-null  object \n",
            " 5   Nodeg          15992 non-null  int64  \n",
            " 6   Earnings_1974  15992 non-null  float64\n",
            " 7   Earnings_1975  15992 non-null  float64\n",
            " 8   Earnings_1978  15992 non-null  float64\n",
            "dtypes: float64(3), int64(2), object(4)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            "Age              0\n",
            "Eduacation       0\n",
            "Race             0\n",
            "Hisp             0\n",
            "MaritalStatus    0\n",
            "Nodeg            0\n",
            "Earnings_1974    0\n",
            "Earnings_1975    0\n",
            "Earnings_1978    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"LabourTrainingEvaluationData.csv\")\n",
        "\n",
        "# Show the first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Display column information and check for null values\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53b6b1f5-53f1-4958-88d5-da9b95c15790",
      "metadata": {
        "id": "53b6b1f5-53f1-4958-88d5-da9b95c15790"
      },
      "source": [
        "#### Step 3: Data Cleaning & Preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a7808c7-c1f2-41dc-b333-eaa893b5e7cf",
      "metadata": {
        "id": "5a7808c7-c1f2-41dc-b333-eaa893b5e7cf",
        "outputId": "acf6b1e9-f5cd-4884-e8be-6a5ff1fe8da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Age          Eduacation  Race  Hisp  MaritalStatus  Nodeg  Earnings_1974  \\\n",
            "0   45  LessThanHighSchool   NaN   NaN            NaN      1      21516.670   \n",
            "1   21        Intermediate   NaN   NaN            NaN      0       3175.971   \n",
            "2   38          HighSchool   NaN   NaN            NaN      0      23039.020   \n",
            "3   48  LessThanHighSchool   NaN   NaN            NaN      1      24994.370   \n",
            "4   18  LessThanHighSchool   NaN   NaN            NaN      1       1669.295   \n",
            "\n",
            "   Earnings_1975  Earnings_1978  \n",
            "0      25243.550      25564.670  \n",
            "1       5852.565      13496.080  \n",
            "2      25130.760      25564.670  \n",
            "3      25243.550      25564.670  \n",
            "4      10727.610       9860.869  \n"
          ]
        }
      ],
      "source": [
        "# Drop rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Binary Encoding: race (0 = not black, 1 = black)\n",
        "df['Race'] = df['Race'].map({0: 0, 1: 1})  # already binary, keeping as-is\n",
        "\n",
        "# Binary Encoding: hispanic\n",
        "df['Hisp'] = df['Hisp'].map({0: 0, 1: 1})  # assuming already binary\n",
        "\n",
        "# Binary Encoding: married\n",
        "df['MaritalStatus'] = df['MaritalStatus'].map({0: 0, 1: 1})  # assuming already binary\n",
        "\n",
        "# View dataset after cleaning\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "901e499b-f931-43aa-9477-0b7f2f00a428",
      "metadata": {
        "id": "901e499b-f931-43aa-9477-0b7f2f00a428"
      },
      "source": [
        "#### Step 4: Define Features and Target Variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e290589d-92d6-46d2-bec9-05cafb5d3c42",
      "metadata": {
        "id": "e290589d-92d6-46d2-bec9-05cafb5d3c42",
        "outputId": "da2692ba-b138-4426-e010-47a3fb31ec5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Education Levels Encoded:\n",
            "[2 1 0 4 3]\n"
          ]
        }
      ],
      "source": [
        "# Label encode the 'educ' column\n",
        "df['Eduacation'] = df['Eduacation'].astype('category').cat.codes\n",
        "\n",
        "# Check the unique codes mapped to education levels\n",
        "print(\"Education Levels Encoded:\")\n",
        "print(df['Eduacation'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb92dda-936c-416c-b0cd-60537873621b",
      "metadata": {
        "id": "5eb92dda-936c-416c-b0cd-60537873621b",
        "outputId": "4bc31891-03f3-406c-ed3a-652016661bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature shape: (15992, 7)\n",
            "Target shape: (15992,)\n"
          ]
        }
      ],
      "source": [
        "# Define the feature columns and target column\n",
        "feature_cols = ['Age', 'Eduacation', 'Race', 'Hisp', 'MaritalStatus', 'Earnings_1974', 'Earnings_1975']\n",
        "target_col = 'Earnings_1978'\n",
        "\n",
        "# Create features (X) and target (y)\n",
        "X = df[feature_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "# Display the shapes\n",
        "print(\"Feature shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd999b7-a40a-4fd2-b2d8-e5f08201988c",
      "metadata": {
        "id": "9fd999b7-a40a-4fd2-b2d8-e5f08201988c"
      },
      "source": [
        "#### Step 5: Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46ed8e6-f42a-49c5-9fa7-6cea5bf29a50",
      "metadata": {
        "id": "e46ed8e6-f42a-49c5-9fa7-6cea5bf29a50",
        "outputId": "918f21ea-fd7e-43a1-89ee-abaf70394cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Reload successful. Final shape: (15992, 4)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Reload the original dataset\n",
        "df = pd.read_csv(\"LabourTrainingEvaluationData.csv\")\n",
        "\n",
        "# Step 2: Drop columns that are entirely null (Race, Hisp, MaritalStatus)\n",
        "df = df.drop(columns=['Race', 'Hisp', 'MaritalStatus'], errors='ignore')  # safely ignore if already dropped\n",
        "\n",
        "# Step 3: Encode 'Eduacation'\n",
        "df['Eduacation'] = df['Eduacation'].astype('category').cat.codes\n",
        "\n",
        "# Step 4: Drop rows that have missing values in required columns\n",
        "required_cols = ['Age', 'Eduacation', 'Earnings_1974', 'Earnings_1975', 'Earnings_1978']\n",
        "df = df.dropna(subset=required_cols)\n",
        "\n",
        "# Step 5: Define features and target\n",
        "feature_cols = ['Age', 'Eduacation', 'Earnings_1974', 'Earnings_1975']\n",
        "target_col = 'Earnings_1978'\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "# Step 6: Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Check\n",
        "print(\" Reload successful. Final shape:\", X.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d482ad0-f5a3-429c-9fe8-7a8ea6e5c312",
      "metadata": {
        "id": "0d482ad0-f5a3-429c-9fe8-7a8ea6e5c312"
      },
      "source": [
        "#### Step 6: Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98e1f271-503a-4d07-8299-c2c8fe17f1ee",
      "metadata": {
        "id": "98e1f271-503a-4d07-8299-c2c8fe17f1ee",
        "outputId": "725beac8-986e-468a-e90b-181d47298414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (12793, 4)\n",
            "Test set size: (3199, 4)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Check shapes\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "109d104f-090a-4ef8-a128-871b22a955b0",
      "metadata": {
        "id": "109d104f-090a-4ef8-a128-871b22a955b0"
      },
      "source": [
        "#### Step 7: Train the Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96370d29-0bfa-451a-82b3-b2afec176571",
      "metadata": {
        "id": "96370d29-0bfa-451a-82b3-b2afec176571",
        "outputId": "b15dd0c7-87d5-462b-a109-5ca3bc5bff94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Coefficients: [-1213.2594495    257.20608236  2737.78065828  4473.53169276]\n",
            "Model Intercept: 14867.312116521296\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Check the learned coefficients\n",
        "print(\"Model Coefficients:\", model.coef_)\n",
        "print(\"Model Intercept:\", model.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f919c593-9698-4eaf-a57a-81de47f789f8",
      "metadata": {
        "id": "f919c593-9698-4eaf-a57a-81de47f789f8"
      },
      "source": [
        "#### Step 8: Make Predictions and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b01d8a-d3df-49d9-a0c3-c670769e9603",
      "metadata": {
        "id": "e7b01d8a-d3df-49d9-a0c3-c670769e9603",
        "outputId": "d592290d-e5b9-44f3-f93f-ef3c70c2281c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Evaluation:\n",
            "Root Mean Squared Error (RMSE): 6975.976804569336\n",
            "R² Score: 0.476299420392424\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Calculate R² Score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Display results\n",
        "print(\"Model Evaluation:\")\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"R² Score:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONCLUSION - The analysis successfully identified key data patterns and relationships through EDA and visualizations. After cleaning and modeling, a machine learning classifier was applied, resulting in accurate outcome predictions. This demonstrates that a structured data-driven approach can effectively support insights and informed decisions.\n",
        "\n"
      ],
      "metadata": {
        "id": "IBpKqI5I0_-1"
      },
      "id": "IBpKqI5I0_-1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}